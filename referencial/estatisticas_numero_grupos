
Chamar a atenção que todos os métodos são para dados contínuos!

Uma crítica que apareceu em alguns trabalhos é de que a maioria das estatísticas não compara o resultado de k = 1 (ou seja, não ter agrupamento). 

Outro problema é na visualização dos dados. Por serem multidimensionais, não conseguimos ver a estrutura deles. Uma simplificação é plotar os CPs, mas não é o ideal (ver cap. 9 do Everitt, cluster analysis)

Mooi (2010) traz um resumo prático sobre as técnicas.

MILLIGAN (1981): ainda não vi detalhes
   - melhores: gama, índice C, point-biserial, tau, W/B, G+

MILLIGAN e COOPER (1985):
   - introdução sobre número de grupos muito boa: falam sobre os dois erros possíveis (1: considerar mais grupos do que realmente há e 2: menos grupos). O segundo é mais grave em situações práticas pois informação acaba sendo perdida.
   - usaram conjuntos de dados artificiais que continham 2, 3, 4 ou 5 grupos não sobrepostos (50 observações cada) e bem separados. Usaram 4 métodos hierárquicos (vizinho + próximo, + distante, distância média e Ward). Na seção "data sets" eles comentam detalhes dos grupos (qual a separação entre eles, que os dados seguiam a normal multivariada, usaram a distância euclidiana, etc.). Além disso, usaram dois critérios externos: índice de Jaccard e estatística Rand ajustada - esses métodos usam informações externas ao processo de agrupamento para validação. No caso, a informação externa era a real estrutura dos grupos.
   - não incluíram métodos gráficos (pois envolvem subjetividade)
   - apresentam os métodos começando daqueles que apresentaram melhor desempenho, mas chamam a atenção que eles foram melhores para grupos bem definido, não quer dizer que são os melhores em qualquer situação
   - Métodos:
   1. Calinski e Harabasz (1974)
   2. Duda e hart (1973)
   3. Índice C - Hubert e Levin (1976)
   4. Gama - adaptação de Baker e Hubert (1975)
   5. Beale (1969)
   6. Cubic clustering criterion - SAS (Ray, 1982; Sarle, 1983)
   7. Point-Biseral 
   8. G+
   9. Mojena (1977)
   10. Davies and Bouldin (1979)
   11. Stepsize
   12. Likelihood ratio, Wolfe (1970)
   13. log (P) Gnanadesikan, Kettenring and Landwher (1977)
   14. Sneath (1977)
   15. Frey and Van Groenewoud (1972)
   16. Log (SSB/SSW). Hartigan (1975)
   17. Tau, Rohlf (1974)
   18. c/k^5. Ratkowsky and Lance (1978; also see Hill, 1980)
   19. n log (|T|/|W|), Scott and Symons (1971)
   20. k2|W|, Marriot (t971)
   21. Bock (1977)
   22. Ball and Hall (1965)
   23. Trace Cov W
   24. Trace W
   25. Lingoes and Cooper (1971)
   26. Trace W-1B, Friedman and Rubin (1967)
   27. Generalized distance, Day (1969)
   28. McClain and Rao (1975) CLUSTISZ
   29. Mountford (1970)
   30. |T|/|W|, Friedman and Rubin (1967)

   Até o método 15 eles não conseguiram explicar as diferenças nos desempenhos. A partir do método 16 houve métodos que apresentaram mais erros do que acertos. Alguns métodos, a partir do 15, começaram a mostrar um padrão de sempre retornar um número constante de grupos, independente de quantos realmente existiam. Bock parece ser melhor quando há poucas dimensões. A estatística Traço de W apresentou desempenho ruim, apesar de ser famosa. A estatística |T|/|W| não acertou em nenhuma das 432 tentativas.
   Discussão: Entre os seis melhores métodos constatados por Milligan (1981), quatro ficaram entre os 10 melhores do artigo de 85: C-index, gama, point-biserial e G+, um no meio (tau) e um no último terço (Mclain e Rao). Os resultados apresentados sugerem ser dependentes dos dados. Alguns métodos dependem da determinação de um valor crítico (Duda e Hart), mas Calinski e Harabasz não. Um autor critica o uso da normal multivariada para gerar os dados e, por isso, alguns dos métodos que foram muito mal poderiam ter ido melhor em outras situações.


TIBSHIRANI et al (2001) - GAP:
   - comentam sobre outros trabalhos: Sugar (1998) e Sugar et al. (1999), Milligan e Cooper (1985), Gordon (1999)
   - a estatística usa uma medida d que costuma ser a euclidiana quadrada (mas parece poder ser outra)
   - Gordon: métodos mais globais têm a desvantagem de serem indefinidos para um grupo e, por isso, não oferecem indicação se os dados deveriam ser agrupados mesmo
   - Por Milligan e Cooper: o melhor é Calinski e Harabasz (1974), mas não testa para k=1. 
   - Simulação de 5 cenários e 6 métodos foram avaliados: CH (Calinski and Harabasz), KL (Krzanowski and Lai), Hartigan (Hartigan, 1975), Silhouette (Kaufman and Rousseeuw, 1990), gap e gappc (o melhor). Quando não há grupos (k=1), GAP é a única aceitável.

DIMITRIADOU et al. (2002): 
   - implementado em R
   - a ênfase é em dados binários de alta dimensão, muito usados em pesquisa de mercado
   - compararam 15 métodos excluindo: aqueles usados apenas para métodos hierárquicos (por não serem indicados para grandes conjuntos de dados); índices similares a medidas usadas para métodos hierárquicos (como gama, Baker e Hubert, point biserial) e outras medidas (likelihood ratio, CCC etc.)
   - como Milligan, também não usaram métodos gráficos (subjetivas)
   - dividiram os 15 métodos em 3 grupos:
   1. SQD e SQEntre: 
      Ball e Hall; Calinski e Harabasz; Hartigan; Ratkowsky e Lance (1978); Xu (1997)
   2. Matrizes T e W (matrizes de dispersão dos dados e soma das matrizes de dispersão em cada grupo): 
      Marriot (1971); Scott e Simmons (1971); Trace covW; Trace W-1B; |T|/|W|
   3. Outros métodos:
      Davies e Bouldin (1979); índice C (Hubert e Levin, 1976); Likelihood NLL (Wedel e Kamakura, 1998); SSI (2000)
   Resultados:
   - Melhores: Ratkowsky-Lance (rank of 2.25), Xu, Scott-Symons, Calinski-Harabasz e C Index.
   - muito recomendados: Ratkowsky-Lance, Davies-Bouldin
   - confiáveis: Calinski e Harabasz, Xu
   - métodos que sempre escolhem o mesmo, independente dos dados: Scott-Symons, Marriot, TraceW-1B, índice C
   - Todos do grupo 3 recomendam frequentemente a solução de 4 grupos
   - índices que escolhem 3 grupos: Ball-Hall, Hartigan, TraceW e NLL
   - O melhor para dados binários: Ratkowsky-Lance

SUGAR (2003):
   - propõe um método (abordagem jump) e compara com:
   1. CH - Calinski e Harabasz
   2. KL - Krzanowski and Lai (1985)
   3. H - Hartigan (1975)
   4. s(i) - Kaufman 	 and Rousseeuw (1990)
   5. GAP - Tibshirani (2001)
   - Cinco cenários de simulação: 
   a) mistura bidimensional de 5 grupos normais (covariância I)
   b) mistura de normais com dimensão alta (10)
   c) dependência entre as dimensões, 4 grupos normais com mesma correlação
   d) 4 grupos normais com correlações diferentes
   e) 4 grupos de não normais (exponenciais) com média 1




MINGOTI (2005): não comenta quais são os melhores
   1. análise da distância
   2. análise do comportamento do nível de similaridade
   3. análise do R2
   4. pseudo-F de Calinski e Harabasz (1974)
   5. correlação semiparcial (Ward)
   6. pseudo t2 de Duda e Hart (1973)
   7. estatística ccc (cubic clustering criterium) por Sarle (1983)


LATTIN (2011): 
  - pseudo-F (Calinski-Harabasz, 1974). Segundo Milligan e Cooper (1985), por simulação Monte Carlo, é a que melhor funciona. Explica a estatística.
  - A seção 8.7.2 trata de validação do agrupamento. O livro ainda comenta sobre como o método de Ward realiza um melhor trabalho de redução da heterogeneidade.

EVERITT (Cluster Analysis, 2011):
   - seção 4.4.4 introduz o tema e comenta que Milligan e Cooper identificaram 5 melhores métodos que foram identificados por Gordon (1998), que afirma que os métodos desenvolvidos por Duda e Hart (1973) e Beale (1969a) são apropriados para estruturas aninhadas inerentes aos métodos hierárquicos (por testarem se um grupo deve ser dividido). Os dois métodos se baseiam na razão entre SQDentro e SQEntre quando o grupo é otimamente dividido em dois. Ainda, comenta que Mojena (1977) sugere outros métodos para agrupamentos hierárquicos: regra da cauda superior - baseia nos tamanhos relativos dos diferentes níveis de fusão no dendrograma -, abordagem de médias móveis - usa ideias de controle de qualidade)
   - cita Baxter (1994): ‘informal and subjective criteria, based on subject expertise, are likely to remain the most common approach. In published studies practice could be improved by
making such criteria more explicit than is sometimes the case’ 
   - seção 5.5 inicia afirmando que a maioria dos métodos são informais e envolvem gráficos do critério X número de grupos. Comenta que Milligan e Cooper fizeram o trabalho mais detalhado de comparação de 30 métodos e que Dimitriadou et al. (2002) incluíram 15 índices para dados binários de grande dimensão. Mas ressalta que os resultados não podem ser generalizados pois o desempenho do método depende da estrutura de grupos, que é desconhecida, mas é útil por identificarem os métodos que são piores para detectar estruturas conhecidas.
   - Os tops de Milligan e Cooper são Calinski and Harabasz (1974) and Duda and Hart (1973). Outro bom baseado na soma de distâncias ao quadrado é o ‘F-test’ proposto por Beale (1969a). O método de Marriott (1971) tende a especificar um número de grupos constante.
   - silhouette plot sugerido por Kaufman and Rousseeuw (1990) é outro método (pacote cluster do R) que pode ajudar. 
   - mais recentemente, GAP de Tibshirani et al. (2001). O método formaliza a ideia de encontrar o "cotovelo" no gráfico do critério X número de grupos. O artigo original faz um estudo de simulação. Ele permite que a solução de um grupo seja avaliada para comparar com as outras (exemplos em Nazareth et al., 2006 ou King et al., 2007). O pacote clusterSim inclui a GAP e o índice silhouette.
   - acrescenta: "In conclusion, it is advisable not to depend on a single rule for selecting the number of groups but to synthesize the results of several techniques. Also, like the cluster criteria themselves, some rules for choosing the number of clusters make assumptions about the cluster structure and will only perform well when these assumptions are met. For example, experience with Beale’s rule suggests that it will only be successful when the clusters are fairly well separated and approximately spherical in shape."
   - exemplos de aplicação dos métodos na seção 5.6
   - cap 9: informações e diretrizes para o uso de agrupamento

FANG (2012):
   - propõe um método bootstrap e o compara com: 
   a) CV a 
   b) silhouette statistic in Kaufman and Rousseeuw (1990), 
   c) gap statistic in Tibshirani et al. (2001)
   d) Sugar and James (2003).
   Resultados:
   - o método proposto vai bem na maior parte das situações
   - Table 1: bootstrap method performs as well as the cross-validation method for selecting the number of clusters, and clearly outperforms the others. The gap statistic also performs very well in Example 1, which is of Gaussian distribution, and in the two-moon example. However, the gap statistic does not perform well in Example 2, where the clusters are non-spherical, and is not working in the bull’s eye example, one of the non-distance based examples. Neither the silhouette statistic nor the jump statistic performs well here. Because the sample sizes in these examples are in hundreds, the advantage of the bootstrap method over the cross-validation method is not clear. 
   - Simulação de 3 e 5 grupos:
   Table 2, we find that the bootstrap method performs slightly better than the cross-validation method. In the settings where p = 2, all the three methods performs very well even when the clusters are seriously overlapped, and the correlation between variables does not cause any problem. Quando os dados seguem a normal, a GAP se sai melhor por ser baseada na distância euclidiana (e afirma-se que a GAP funciona bem com grupos normais ou outras distribuições simétricas, mas falha quando não são simétricas)


FUJITA (2014): propõem um método não paramétrico baseado no método silhouette de Rousseeuw (1987)
   - comentam que existem vários métodos, mas que ainda é um problema difícil e ainda não resolvido devido à ausência de uma definição clara de grupo e especialmente porque epende do método de agrupamento e das características dos dados (forma e escala)
   - uma dificuldade da maioria dos métodos é classificar corretamente quando os pontos dentro do mesmo grupo são correlacionados ou não são normais, em situações de muitas variáveis ou quando há um grupo dominante
   - compara seu método com (mostrando todas as estatísticas):
   (a) Bayesian Information Criterion (BIC) (Celeux and Govaert, 1992) for a mixture of Gaussian distributions, 
   (b) the Calinski and Harabasz (CH) index Calinski and Harabasz (1974), 
   (c) the Krzanowski and Lai (KL) index Krzanowski and Lai (1985), 
   (d) the silhouette method (Rousseeuw, 1987), 
   (e) the gap statistic (Tibshirani et al., 2001), 
   (f) the prediction strength (Tibshirani and Walther, 2005), and (g) the jump method (Sugar and James, 2003).
   - os autores afirmam que seu método se sai melhor do que todos os comparados quando os dados são correlacionados, não normais, muitas variáveis ou com grupo dominante
   - 7 cenários de simulação (bem variados)
   - usam k-médias e distância euclidiana (mas outros podem ser usados)
   - gap statistic superestima o número de grupos quando os dados seguem distribuição derivada da exponencial
   


NBCLUST (2014):
1. "ch" (Calinski and Harabasz 1974)
2. "duda" (Duda and Hart 1973)
3. "pseudot2" (Duda and Hart 1973)
4. "cindex" (Hubert and Levin 1976)
5. "gamma" (Baker and Hubert 1975)
6. "beale" (Beale 1969)
7. "ccc" (Sarle 1983)
8. "ptbiserial" (Milligan 1980, 1981)
9. "gplus" (Rohlf 1974; Milligan 1981)
10. "db" (Davies and Bouldin 1979)
11. "frey" (Frey and Van Groenewoud 1972)
12. "hartigan" (Hartigan 1975)
13. "tau" (Rohlf 1974; Milligan 1981)
14. "ratkowsky" (Ratkowsky and Lance 1978)
15. "scott" (Scott and Symons 1971)
16. "marriot" (Marriot 1971)
17. "ball" (Ball and Hall 1965)
18. "trcovw" (Milligan and Cooper 1985)
19. "tracew" (Milligan and Cooper 1985)
20. "friedman" (Friedman and Rubin 1967)
21. "mcclain" (McClain and Rao 1975)
22. "rubin" (Friedman and Rubin 1967)
23. "kl" (Krzanowski and Lai 1988)
24. "silhouette" (Rousseeuw 1987)
25. "gap" (Tibshirani et al. 2001)
26. "dindex" (Lebart et al. 2000)
27. "dunn" (Dunn 1974)
28. "hubert" (Hubert and Arabie 1985)
29. "sdindex" (Halkidi et al. 2000)
30. "sdbw" (Halkidi and Vazirgiannis 2001)
